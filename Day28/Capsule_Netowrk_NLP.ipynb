{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# <center>Beginner's Guide to Capsule Networks</center>\n",
    "\n",
    "_Author: Zafar_\n",
    "\n",
    "_Last Updated: 03/30/18_\n",
    "\n",
    "--------\n",
    "\n",
    "In the recently concluded [Toxic Comments Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), Capsule Network (aka CapsNet) proved to be a huge success. This notebook introduces and implements a Capsule Network in Keras and evaluates its performance in the DonorsChoose.Org Application Screening Competition.\n",
    "\n",
    "## Contents\n",
    "1. [Introduction to Capsule Networks](#introduction)\n",
    "    * 1.1 [Human Visual Recognition](#human)\n",
    "    * 1.2 [Capsules](#capsules)\n",
    "    * 1.3 [Routing by Agreement](#routing)\n",
    "    * 1.4 [Mathematics behind CapsNet](#maths)\n",
    "    * 1.5 [The Dyanmic Routing Algorithm](#algo)\n",
    "    * 1.6 [A word about squash function](#squash)\n",
    "    * 1.7 [The advantage of Capsule Networks](#advantage)\n",
    "2. [Boilerplate Code](#boilerplate)\n",
    "3. [CapsNet implementation](#capsnet_model)\n",
    "4. [Training](#training)\n",
    "5. [Submission](#submission)\n",
    "6. [Conclusion](#conclusion)\n",
    "7. [References](#references)\n",
    "\n",
    "Before you read further, it is important to note that the examples presented here are just for the purpose of understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7a089293-2c3b-4bcb-bdfd-dd48854555b6",
    "_uuid": "95390dc737aa3971e40034808790c153f7ed7398"
   },
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction to Capsule Networks\n",
    "<a id=\"human\"></a>\n",
    "#### Human Visual Recognition\n",
    "Any real object is made up of several smaller objects. For example, a tree consists of a *trunk*, a *crown* and *roots*. These parts form a hierarchy. The crown of a tree further consists of branches and branches have leaves.\n",
    "\n",
    "![Parts of a tree](https://study.com/cimages/multimages/16/tree_parts_diagram.png)\n",
    "\n",
    "Whenever we see some object, our eyes make some **fixation points** and the relative positions and natures of these fixation points help our brain in recognizing that object. By doing so, our brain does not have to process every detail. Just by seeing some leaves and branches, our brain recognizes there is a crown of a tree. And the crown is standing on a trunk below which are some roots. Combining this hierarchical information, our brain knows that there is a tree. From now on, we will call **the parts of the objects** as entities.\n",
    "\n",
    "![Parts of a tree](https://raw.githubusercontent.com/zaffnet/images/master/images/tree.png)\n",
    "\n",
    ">*Each complex object can be thought of a hierarchy of simpler objects.*\n",
    "<a id=\"capsules\"></a>\n",
    "#### Capsules\n",
    "\n",
    "The assumption behind CapsNet is that there are capsules (groups of neurons) that tell whether certain objects (**entities**) are present in an image. Corresponding to each entity, there is a capsule which gives:\n",
    "1. the probability that the entity exists\n",
    "2. The **instantiation parameters** of that entity.\n",
    "\n",
    "Instantiation parameters are the properties of that entity in an image (like \"position\", \"size\", \"position\", \"hue\", etc). For example, a **rectangle** is a simple geometric object. The capsule corresponding to a rectangle will tell us about its instantiation parameters. \n",
    "\n",
    "![Rectangle capsule](https://raw.githubusercontent.com/zaffnet/images/master/images/rectangle.png)\n",
    "\n",
    "\n",
    "From the figure above, our imaginary capsule consists of 6 neurons each corresponding to some property of the rectangle. The length of this vector will give us the probability of the presence of a rectangle. So, the probability that a rectangle is present will be: $$\\sqrt[]{1.3^2 + 0.6^2 + 7.4^2 + 6.5^2 + 0.5^2 + 1.4^2} = 10.06$$\n",
    "\n",
    "But wait a minute! If the length of the output vector represents the probability of the existence of an entity, shouldn't it be less than or equal to 1 (i.e., $0 \\leq P \\leq 1$)? Yes, and that is why we transform the capsule output $s$ like this:\n",
    "\n",
    "![squashing function](https://raw.githubusercontent.com/zaffnet/images/master/images/squash.png)\n",
    "\n",
    "\n",
    "This non-linear transformation is called **squashing** function and it serves as an activation function for capsule networks (just like ReLU is used in CNNs).\n",
    "\n",
    ">*A capsule is a group of neurons whose activation $v = <v_1, v_2, ..., v_n>$ represents the instantiation parameters of an entity and whose length represents the probability of the existence of that entity.*\n",
    "<a id=\"routing\"></a>\n",
    "#### Routing by agreement\n",
    "A CapsNet consists of several layers. Capsules in the lower layer correspond to simple entities (like rectangles, triangles, circles, etc). These low-level capsules bet on the presence of more complex entities and their bets are \"combined\" to get the output of high-level capsules (doors, windows, etc). For example, the presence of a *rectangle* (angle with x-axis = 0, size = 5, position = 0,...) and a *triangle* (angle with x-axis = 6, size = 5, position = 5,...) work together to bet on the presence of a *house* (a higher-level entity). \n",
    "\n",
    "There is a **coupling effect** too. When some low-level capsules agree on the presence of a high-level entity, the high-level capsule corresponding to that entity sends a feedback to these low-level capsules which *increases* their bet on that high-level capsule. To understand this, let's assume we have two levels of capsules: \n",
    "1. Lower level corresponds to rectangles, triangles and circles\n",
    "2. High level corresponds to houses, boats, and cars\n",
    "\n",
    "If there is an image of a house, the capsules corresponding to rectangles and triangles will have large activation vectors. Their relative positions (coded in their instantiation parameters) will bet on the presence of high-level objects. Since they will agree on the presence of house, the output vector of the house capsule will become large. This, in turn, will make the predictions by the rectangle and the traingle capsules larger. This cycle will repeat 4-5 times after which the bets on the presence of a house will be considerably larger than the bets on the presence of a boat or a car.\n",
    "<a id=\"maths\"></a>\n",
    "#### Mathematics behind CapsNet\n",
    "Suppose layer $l$ and $l+1$ have $m$ and $n$ capsules respectively. Our task is to calculate the activations of the capsules at layer $l+1$ given the activations at layer $l$. Let $u$ denotes the activations of capsules at layer $l$. We have to calculate $v$, the activations of capsules at layer $l+1$. \n",
    "\n",
    "For a capsule $j$ at layer $l+1$, \n",
    "\n",
    "1. We first calculate the **prediction vectors** by the capsules at layer $l$. The prediction vector by a capsule $i$ (of layer $l$) for the capsule $j$ (of layer $l+1$) is given by:\n",
    "    $$\\boldsymbol{\\hat{\\textbf{u}}}_{j|i} = \\boldsymbol{\\textbf{W}}_{ij}\\boldsymbol{\\textbf{u}}_i$$ $\\textbf{W}_{ij}$ is the weight matrix.\n",
    "\n",
    "2. We then calculate the **output vector** for the capsule $j$. The output vector is the weighted sum of all the prediction vectors given by the capsules of layer $l$ for the capsule $j$:\n",
    "    $$s_j = \\sum_{i=1}^{m}{c_{ij}\\boldsymbol{\\hat{\\textbf{u}}}_{j|i}}$$ The scalar $\\textbf{c}_{ij}$ is called **coupling coefficient** between capsule $i$ (of layer $l$) and $j$ (of layer $l+1$). These coefficients are determied by an algorithm called the **iterative dynamic routing algorithm**.\n",
    "\n",
    "3. We apply the **squashing** function on the output vector to get the activation $\\textbf{v}_j$ of the capsule $j$:\n",
    "    $$\\textbf{v}_j = \\textbf{squash}(\\textbf{s}_j)$$\n",
    "    \n",
    "<a id=\"algo\"></a>\n",
    "#### The dynamic routing algorithm\n",
    "The activation vectors of layer $l+1$ send feedback signals to the capsules at layer $l$. If the prediction vector of capsule $i$ (of layer $l$) for a capsule $j$ (of layer $l+1$) is in agreement with the activation vector of capsule $j$, their dot product should be high. Hence the \"weight\" of the prediction vector $\\boldsymbol{\\hat{\\textbf{u}}}_{j|i}$ is increased in the output vector of $j$. In other words, those prediction vectors that helped the activation vector have a lot more weight in the output vector (and consequently the activation vector). This cycle of mutual help continues for 4-5 rounds. \n",
    "\n",
    "But the predictions of a low-level capsule for high-level capsules should sum to one. That is why for a capsule $i$ (of layer $l$), \n",
    "$$c_{ij} = \\frac{\\exp(b_{ij})}{\\sum_{k}{\\exp(b_{ik})}}$$ Clearly, $$\\sum_{k}{c_{ik}} = 1$$ The logit $b_{ij}$ indicates whether capsules $i$ (of layer $l$) and $j$ (of layer $l+1$) have strong coupling. In other words, it is a measure of how much the presence of the capsule $j$ is explained by the capsule $i$. Initially, all $b_{ij}$ should be equal.\n",
    "\n",
    "**Routing algorithm:**\n",
    ">Given: Prediction vectors $\\boldsymbol{\\hat{\\textbf{u}}}_{j|i}$, number of routing iterations $r$\n",
    "\n",
    ">for all capsule $i$ in layer $l$ and capsule $j$ in layer $l+1$: $b_{ij} = 0$ \n",
    "\n",
    ">for $r$ iterations do:\n",
    "\n",
    ">>for all capsules $i$ in the layer $l$: $c_i = softmax(b_i)$ \n",
    ">>**(the bets of a capsule on high-level capsules should sum to 1)**\n",
    "\n",
    ">>for all capsules $j$ in the layer $l+1$: $s_j = \\sum_{i=1}^{m}{c_{ij}\\boldsymbol{\\hat{\\textbf{u}}}_{j|i}}$\n",
    ">>**(the output vector is the weighted sum of prediction vectors)**\n",
    "\n",
    ">>for all capsules $j$ in the layer $l+1$: $\\textbf{v}_j = \\textbf{squash}(\\textbf{s}_j)$\n",
    ">>**(apply the activation function)**\n",
    "\n",
    ">> for all capsule $i$ in layer $l$ and capsule $j$ in layer $l+1$: $b_{ij} = b_{ij} + \\boldsymbol{\\hat{\\textbf{u}}}_{j|i} \\cdot \\textbf{v}_j$\n",
    "\n",
    "> return $\\textbf{v}_j$\n",
    "\n",
    "The last line in the loop is very important. It is here that the routing happens. If the product has $\\boldsymbol{\\hat{\\textbf{u}}}_{j|i} \\cdot \\textbf{v}_j$ is large, it will increase $b_{ij}$ which will increase the corresponding coupling coefficient $c_{ij}$, which in turn, will make the product $\\boldsymbol{\\hat{\\textbf{u}}}_{j|i} \\cdot \\textbf{v}_j$ even larger.\n",
    "\n",
    "This is how CapsNet works. At this point, you will find no difficulty in reading the [original paper](https://arxiv.org/pdf/1710.09829.pdf) by Hinton.\n",
    "<a id=\"squash\"></a>\n",
    "#### A word about squashing function:\n",
    "The derivative of $\\|\\mathbf{s}\\|$ is undefined when $\\|\\mathbf{s}\\|=0$, and it may blow up during training: if a vector is zero, the gradients will be `nan`, so when the optimizer updates the variables, they will also become `nan`. The solution is to implement the norm manually by computing the square root of the sum of squares plus a tiny epsilon value: $\\|\\mathbf{s}\\| \\approx \\sqrt{\\sum\\limits_i{{s_i}^2}\\,\\,+ \\epsilon}$.\n",
    "<a id=\"advantage\"></a>\n",
    "#### What is the advantage?\n",
    "In a CNN, there are pooling layers. We generally use MaxPool which is a very primitive type of routing mechanism. The most active feature in a local pool (say 4x4 grid) is routed to the higher layer and the higher-level detectors don't have a say in the routing. Compare this with the routing-by-agreement mechanism introduced in the CapsNet. Only those features that agree with high-level detectors are routed. This is the advantage of CapsNet over CNN. It has a superior dynamic routing mechanism (dynamic because the information to be routed is determined in real time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1661d3c5-b9d6-4340-a268-26c6e7fdabfe",
    "_uuid": "62359e3ac6e9ebf7c96d5ece77d74051cb655593"
   },
   "source": [
    "<a id=\"boilerplate\"></a>\n",
    "## Boilerplate Code\n",
    "#### Essential imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4c52bea6-9dcf-46b3-b07a-d6bc156182b6",
    "_kg_hide-output": true,
    "_uuid": "e900d3cf3df9e77110ab7d79f1ccbe3dd068b8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import nltk\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "449b057d-d61f-462b-a1a4-3b80b43106c0",
    "_uuid": "1f1ad2cc343f8e2c74bade9b631e9af7680e5ddd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_sentences(sentences, words_dict):\n",
    "    tokenized_sentences = []\n",
    "    for sentence in tqdm.tqdm(sentences):\n",
    "        if hasattr(sentence, \"decode\"):\n",
    "            sentence = sentence.decode(\"utf-8\")\n",
    "        tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "        result = []\n",
    "        for word in tokens:\n",
    "            word = word.lower()\n",
    "            if word not in words_dict:\n",
    "                words_dict[word] = len(words_dict)\n",
    "            word_index = words_dict[word]\n",
    "            result.append(word_index)\n",
    "        tokenized_sentences.append(result)\n",
    "    return tokenized_sentences, words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "07acd58d-93f6-4a65-8b2b-bdc20b0f1fb2",
    "_uuid": "b4715a55f35ba98018ab948f2f6859fbcb9da505",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_embedding_list(file_path):\n",
    "    embedding_word_dict = {}\n",
    "    embedding_list = []\n",
    "    f = open(file_path)\n",
    "\n",
    "    for index, line in enumerate(f):\n",
    "        if index == 0:\n",
    "            continue\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "        except:\n",
    "            continue\n",
    "        embedding_list.append(coefs)\n",
    "        embedding_word_dict[word] = len(embedding_word_dict)\n",
    "    f.close()\n",
    "    embedding_list = np.array(embedding_list)\n",
    "    return embedding_list, embedding_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "8e09726c-5bd1-4344-8290-69f6b87fda18",
    "_uuid": "4a0c79a8e741d3f4f6a829c79e0ce2dd16db1593",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_embedding_list(embedding_list, embedding_word_dict, words_dict):\n",
    "    cleared_embedding_list = []\n",
    "    cleared_embedding_word_dict = {}\n",
    "\n",
    "    for word in words_dict:\n",
    "        if word not in embedding_word_dict:\n",
    "            continue\n",
    "        word_id = embedding_word_dict[word]\n",
    "        row = embedding_list[word_id]\n",
    "        cleared_embedding_list.append(row)\n",
    "        cleared_embedding_word_dict[word] = len(cleared_embedding_word_dict)\n",
    "\n",
    "    return cleared_embedding_list, cleared_embedding_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "eded41b7-677b-4079-aa27-64e532c9bc52",
    "_uuid": "4fe8621eb24bd507cafbdd31c4c2146110c656ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tokens_to_ids(tokenized_sentences, words_list, embedding_word_dict, sentences_length):\n",
    "    words_train = []\n",
    "\n",
    "    for sentence in tokenized_sentences:\n",
    "        current_words = []\n",
    "        for word_index in sentence:\n",
    "            word = words_list[word_index]\n",
    "            word_id = embedding_word_dict.get(word, len(embedding_word_dict) - 2)\n",
    "            current_words.append(word_id)\n",
    "\n",
    "        if len(current_words) >= sentences_length:\n",
    "            current_words = current_words[:sentences_length]\n",
    "        else:\n",
    "            current_words += [len(embedding_word_dict) - 1] * (sentences_length - len(current_words))\n",
    "        words_train.append(current_words)\n",
    "    return words_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "681bea70-8a75-46af-aaed-b9726b4d0bda",
    "_uuid": "d438dd177f790e46e2bbf82574fb7d63b1416669"
   },
   "source": [
    "<a id=\"capsnet_model\"></a>\n",
    "### Capsule Network Model\n",
    "The Architecture of our CapsNet is very similar to general architecture, except for an addition Capsule Layer.\n",
    "\n",
    "![Text Classification](https://raw.githubusercontent.com/zaffnet/images/master/images/comparison.jpg)\n",
    "\n",
    "\n",
    "#### Advantage of Capsule Layer in Text Classification\n",
    "As you can see, we have used Capsule layer instead of Pooling layer. Capsule Layer eliminates the need for forced pooling layers like MaxPool. In many cases, this is desired because we get translational invariance without losing minute details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a631c494-99ae-41db-a119-cd8f98209e03",
    "_kg_hide-output": true,
    "_uuid": "327232d13ddd4549edec2b185bf96c0bf6b1ed87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten\n",
    "from keras.layers import concatenate, GRU, Input, K, LSTM, MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4758b588-6cf9-41d9-97f6-85ea9c7e59ab",
    "_uuid": "88116eab2cbc77c61dc4776d40e01f5ef5c62f5c"
   },
   "source": [
    "#### CapsNet parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "08637271-0dce-4d53-a807-cd4516cb567d",
    "_uuid": "a7f0a6791da9b5d0c4a57b9ae08d7667e37ad40d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru_len = 128\n",
    "Routings = 5\n",
    "Num_capsule = 10\n",
    "Dim_capsule = 16\n",
    "dropout_p = 0.3\n",
    "rate_drop_dense = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "aa7b6069-897e-4e50-b3a9-14f9fe2de59d",
    "_uuid": "57bd4165c2cf1af5e268bd253c6d201d222a5f8a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "46eb605f-9281-4171-82da-ed4f541db6b6",
    "_uuid": "8be15963a074dde02ace1a1d3ca103bb28f2eb26"
   },
   "source": [
    "#### Capsule Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "182cd19b-cdb3-4897-95d6-a32af7eddb94",
    "_uuid": "6fe7d0b616cd46e74c72004f9ad90b1aec2bab22",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "4b606082-b041-4c50-aab1-305295534758",
    "_uuid": "4f4444cbe95d966d5e632f5af88ebb9b932dfed7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(embedding_matrix, sequence_length, dropout_rate, recurrent_units, dense_size):\n",
    "    input1 = Input(shape=(sequence_length,))\n",
    "    embed_layer = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n",
    "                                weights=[embedding_matrix], trainable=False)(input1)\n",
    "    embed_layer = SpatialDropout1D(rate_drop_dense)(embed_layer)\n",
    "\n",
    "    x = Bidirectional(\n",
    "        GRU(gru_len, activation='relu', dropout=dropout_p, recurrent_dropout=dropout_p, return_sequences=True))(\n",
    "        embed_layer)\n",
    "    capsule = Capsule(num_capsule=Num_capsule, dim_capsule=Dim_capsule, routings=Routings,\n",
    "                      share_weights=True)(x)\n",
    "    capsule = Flatten()(capsule)\n",
    "    capsule = Dropout(dropout_p)(capsule)\n",
    "    output = Dense(1, activation='sigmoid')(capsule)\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "34865130-068a-41f7-887f-b9c5920586e2",
    "_uuid": "6e612062548efc64ad675350650482c59c868a39",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _train_model(model, batch_size, train_x, train_y, val_x, val_y):\n",
    "    num_labels = train_y.shape[1]\n",
    "    patience = 5\n",
    "    best_loss = -1\n",
    "    best_weights = None\n",
    "    best_epoch = 0\n",
    "    \n",
    "    current_epoch = 0\n",
    "    \n",
    "    while True:\n",
    "        model.fit(train_x, train_y, batch_size=batch_size, epochs=1)\n",
    "        y_pred = model.predict(val_x, batch_size=batch_size)\n",
    "\n",
    "        total_loss = 0\n",
    "        for j in range(num_labels):\n",
    "            loss = log_loss(val_y[:, j], y_pred[:, j])\n",
    "            total_loss += loss\n",
    "\n",
    "        total_loss /= num_labels\n",
    "\n",
    "        print(\"Epoch {0} loss {1} best_loss {2}\".format(current_epoch, total_loss, best_loss))\n",
    "\n",
    "        current_epoch += 1\n",
    "        if total_loss < best_loss or best_loss == -1:\n",
    "            best_loss = total_loss\n",
    "            best_weights = model.get_weights()\n",
    "            best_epoch = current_epoch\n",
    "        else:\n",
    "            if current_epoch - best_epoch == patience:\n",
    "                break\n",
    "\n",
    "    model.set_weights(best_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "13a836bc-d251-438a-b135-73fa4428b193",
    "_uuid": "1f15bfa8b13df55230ace8c32177810a95ce04e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_folds(X, y, X_test, fold_count, batch_size, get_model_func):\n",
    "    print(\"=\"*75)\n",
    "    fold_size = len(X) // fold_count\n",
    "    models = []\n",
    "    result_path = \"predictions\"\n",
    "    if not os.path.exists(result_path):\n",
    "        os.mkdir(result_path)\n",
    "    for fold_id in range(0, fold_count):\n",
    "        fold_start = fold_size * fold_id\n",
    "        fold_end = fold_start + fold_size\n",
    "\n",
    "        if fold_id == fold_size - 1:\n",
    "            fold_end = len(X)\n",
    "\n",
    "        train_x = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "        train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "\n",
    "        val_x = np.array(X[fold_start:fold_end])\n",
    "        val_y = np.array(y[fold_start:fold_end])\n",
    "\n",
    "        model = _train_model(get_model_func(), batch_size, train_x, train_y, val_x, val_y)\n",
    "        train_predicts_path = os.path.join(result_path, \"train_predicts{0}.npy\".format(fold_id))\n",
    "        test_predicts_path = os.path.join(result_path, \"test_predicts{0}.npy\".format(fold_id))\n",
    "        train_predicts = model.predict(X, batch_size=512, verbose=1)\n",
    "        test_predicts = model.predict(X_test, batch_size=512, verbose=1)\n",
    "        np.save(train_predicts_path, train_predicts)\n",
    "        np.save(test_predicts_path, test_predicts)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "078ec9ba-e9a8-4868-a5b3-42675d2d00d0",
    "_uuid": "6f385e91ebc684e8aa7a5bcc95c915fc07b98abc"
   },
   "source": [
    "<a id=\"training\"></a>\n",
    "### Training\n",
    "\n",
    "#### IMPORTANT\n",
    "Due to time limit in Kaggle kernels, I have restricted the model size and trained it on a small part of the  dataset. The commented values are those for which this model is trained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "cd4771aa-4355-4edd-82bd-07f9779ca9b3",
    "_uuid": "7a6033641b32dd560b545b6b4fbba034997e486b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_file_path = \"../input/donorschooseorg-preprocessed-data/train_preprocessed.csv\"\n",
    "train_file_path = \"train.csv\"\n",
    "\n",
    "# test_file_path = \"../input/donorschooseorg-preprocessed-data/test_preprocessed.csv\"\n",
    "test_file_path = \"test.csv\"\n",
    "\n",
    "# embedding_path = \"../input/fatsttext-common-crawl/crawl-300d-2M/crawl-300d-2M.vec\"\n",
    "embedding_path = \"glove.840B.300d.txt\"\n",
    "\n",
    "batch_size = 128 # 256\n",
    "recurrent_units = 16 # 64\n",
    "dropout_rate = 0.3 \n",
    "dense_size = 8 # 32\n",
    "sentences_length = 10 # 300\n",
    "fold_count = 2 # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "66f3990e-32b3-4428-bbb8-51be54b493cb",
    "_uuid": "30d622993e434548e6b26bcf46317c168a160206",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNKNOWN_WORD = \"_UNK_\"\n",
    "END_WORD = \"_END_\"\n",
    "NAN_WORD = \"_NAN_\"\n",
    "CLASSES = [\"OUTPUT_LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "63f8cf0d-9d52-41df-8a91-eb008aec7fb3",
    "_kg_hide-output": true,
    "_uuid": "66a9d49708a013d1da00b945e1dddaf87fe340fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "list_sentences_train = train_data[\"TEXT\"].fillna(NAN_WORD).values\n",
    "list_sentences_test = test_data[\"TEXT\"].fillna(NAN_WORD).values\n",
    "y_train = train_data[CLASSES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "991fa3fc-bd61-44db-9c9e-8b064c4480ba",
    "_kg_hide-output": true,
    "_uuid": "f0c0539daa59465f541c4b9628f4fd2ad4f88a1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/40890 [00:00<20:54, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences in train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40890/40890 [14:28<00:00, 47.08it/s]\n",
      "  0%|          | 7/10223 [00:00<02:32, 67.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing sentences in test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10223/10223 [03:31<00:00, 48.38it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizing sentences in train set...\")\n",
    "tokenized_sentences_train, words_dict = tokenize_sentences(list_sentences_train, {})\n",
    "print(\"Tokenizing sentences in test set...\")\n",
    "tokenized_sentences_test, words_dict = tokenize_sentences(list_sentences_test, words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "427256fc-d559-42a5-a11f-a245f46762a7",
    "_kg_hide-output": true,
    "_uuid": "527fe0400d6baf2c35e7371234a3ae01385bfd5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Embedding\n",
    "words_dict[UNKNOWN_WORD] = len(words_dict)\n",
    "print(\"Loading embeddings...\")\n",
    "embedding_list, embedding_word_dict = read_embedding_list(embedding_path)\n",
    "embedding_size = len(embedding_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "1457f67c-b4a1-4f57-8cf7-e10845a34ff7",
    "_kg_hide-output": true,
    "_uuid": "8af39d90468df68ca6566422dba9b05458c153ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "embedding_list, embedding_word_dict = clear_embedding_list(embedding_list, embedding_word_dict, words_dict)\n",
    "\n",
    "embedding_word_dict[UNKNOWN_WORD] = len(embedding_word_dict)\n",
    "embedding_list.append([0.] * embedding_size)\n",
    "embedding_word_dict[END_WORD] = len(embedding_word_dict)\n",
    "embedding_list.append([-1.] * embedding_size)\n",
    "\n",
    "embedding_matrix = np.array(embedding_list)\n",
    "\n",
    "id_to_word = dict((id, word) for word, id in words_dict.items())\n",
    "train_list_of_token_ids = convert_tokens_to_ids(\n",
    "    tokenized_sentences_train,\n",
    "    id_to_word,\n",
    "    embedding_word_dict,\n",
    "    sentences_length)\n",
    "test_list_of_token_ids = convert_tokens_to_ids(\n",
    "    tokenized_sentences_test,\n",
    "    id_to_word,\n",
    "    embedding_word_dict,\n",
    "    sentences_length)\n",
    "X_train = np.array(train_list_of_token_ids)\n",
    "X_test = np.array(test_list_of_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "c8222729-dba3-4e74-80ea-a53e45a7d1ba",
    "_kg_hide-output": true,
    "_uuid": "1e3081e1c8e3fa5644e28639f3908519a270bea0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_model_func = lambda: get_model(\n",
    "    embedding_matrix,\n",
    "    sentences_length,\n",
    "    dropout_rate,\n",
    "    recurrent_units,\n",
    "    dense_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "4b24361b-e012-499b-98f4-ddd964cf74c9",
    "_kg_hide-output": true,
    "_uuid": "c60cae2220beb0190fd1f41d685e30a811ed8f7d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data, test_data, list_sentences_train, list_sentences_test\n",
    "del tokenized_sentences_train, tokenized_sentences_test, words_dict\n",
    "del embedding_list, embedding_word_dict\n",
    "del train_list_of_token_ids, test_list_of_token_ids\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "065825da-aa27-4ba4-a460-1bc5c87b111b",
    "_kg_hide-output": true,
    "_uuid": "abea6ac5481a36615f7cc83851de848c193c5334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train models...\n",
      "===========================================================================\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 32s 2ms/step - loss: 0.2277 - acc: 0.9401\n",
      "Epoch 0 loss 0.2231085020324498 best_loss -1\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2241 - acc: 0.9415\n",
      "Epoch 1 loss 0.2225255858030113 best_loss 0.2231085020324498\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 28s 1ms/step - loss: 0.2244 - acc: 0.9415\n",
      "Epoch 2 loss 0.22225136021404956 best_loss 0.2225255858030113\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2243 - acc: 0.9415\n",
      "Epoch 3 loss 0.2221489927287089 best_loss 0.22225136021404956\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2239 - acc: 0.9415\n",
      "Epoch 4 loss 0.22253928681542628 best_loss 0.2221489927287089\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2237 - acc: 0.9415\n",
      "Epoch 5 loss 0.22209623905641726 best_loss 0.2221489927287089\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2243 - acc: 0.9415\n",
      "Epoch 6 loss 0.2224147018009656 best_loss 0.22209623905641726\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2235 - acc: 0.9415\n",
      "Epoch 7 loss 0.22301432928582893 best_loss 0.22209623905641726\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2242 - acc: 0.9415\n",
      "Epoch 8 loss 0.22222085755476015 best_loss 0.22209623905641726\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2249 - acc: 0.9415\n",
      "Epoch 9 loss 0.22222658962404912 best_loss 0.22209623905641726\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2240 - acc: 0.9415\n",
      "Epoch 10 loss 0.2221797796158955 best_loss 0.22209623905641726\n",
      "40890/40890 [==============================] - 19s 476us/step\n",
      "10223/10223 [==============================] - 5s 473us/step\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 29s 1ms/step - loss: 0.2280 - acc: 0.9393\n",
      "Epoch 0 loss 0.2227943322380996 best_loss -1\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 26s 1ms/step - loss: 0.2239 - acc: 0.9416\n",
      "Epoch 1 loss 0.22291087630829154 best_loss 0.2227943322380996\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 26s 1ms/step - loss: 0.2238 - acc: 0.9416\n",
      "Epoch 2 loss 0.2228914883014158 best_loss 0.2227943322380996\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2232 - acc: 0.9416\n",
      "Epoch 3 loss 0.2230238996591901 best_loss 0.2227943322380996\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 26s 1ms/step - loss: 0.2234 - acc: 0.9416\n",
      "Epoch 4 loss 0.2238802792024761 best_loss 0.2227943322380996\n",
      "Epoch 1/1\n",
      "20445/20445 [==============================] - 27s 1ms/step - loss: 0.2237 - acc: 0.9416\n",
      "Epoch 5 loss 0.22451831617370507 best_loss 0.2227943322380996\n",
      "40890/40890 [==============================] - 19s 468us/step\n",
      "10223/10223 [==============================] - 5s 465us/step\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting to train models...\")\n",
    "models = train_folds(X_train, y_train, X_test, fold_count, batch_size, get_model_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d4d100f-f7ca-4ce4-886e-24ffcae3457b",
    "_uuid": "0814f5a555073ef039a74b853270af2f2dd11f72"
   },
   "source": [
    "<a id=\"submission\"></a>\n",
    "### Submission\n",
    "\n",
    "We trained the model for 10 folds using default parameters. We will make a rank-averaged submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "e56f9fd2-d532-41e0-9d89-0786575303e1",
    "_kg_hide-output": true,
    "_uuid": "0baf1585fd832f28798c803dd7066f113e883f50"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-90499ce666ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredict_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredict_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_predicts0.npy\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rank averaging on \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "LABELS = [\"OUTPUT_LABEL\"]\n",
    "\n",
    "#base = \" \"\n",
    "predict_list = []\n",
    "for j in range(10):\n",
    "    predict_list.append(np.load(\"test_predicts0.npy\"%j))\n",
    "    \n",
    "print(\"Rank averaging on \", len(predict_list), \" files\")\n",
    "predcitions = np.zeros_like(predict_list[0])\n",
    "for predict in predict_list:\n",
    "    predcitions = np.add(predcitions.flatten(), rankdata(predict)/predcitions.shape[0])  \n",
    "predcitions /= len(predict_list)\n",
    "\n",
    "#submission = pd.read_csv('../input/donorschoose-application-screening/sample_submission.csv')\n",
    "#submission[LABELS] = predcitions\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5073f22-4b02-458f-8346-b72a5a5f0828",
    "_uuid": "13c1c13f73a41bf1bdf6df7caca8efc62ad02665"
   },
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "### Conclusion\n",
    "We can see that a Capsule Network can be helpful in Text Classification. Even without any hyperparameter tuning, one can build a strong baseline using CapsNet. \n",
    "<a id=\"references\"></a>\n",
    "### References\n",
    "* [Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829)\n",
    "* [Understanding Hinton’s Capsule Networks](https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b)\n",
    "* [Capsule Networks (CapsNets) – Tutorial](https://www.youtube.com/watch?v=pPN8d0E3900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "afe4dbf8-491a-4869-bf1d-ffbb25df8e9f",
    "_kg_hide-input": true,
    "_uuid": "951d44d36e9a89315e8d647c8db99476ade5a688"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://www.youtube.com/embed/pPN8d0E3900\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f2a68487d30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('pPN8d0E3900', width=800, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "931ddf0c-7026-41ec-8bd2-479bcd18cddf",
    "_uuid": "6a402e8e6e57959942ed3d82db7d61035854e29e",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
